{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4136b7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 - train.csv:\n",
      "        id  N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders  \\\n",
      "0        0     999  D-penicillamine  21532   M       N            N       N   \n",
      "1        1    2574          Placebo  19237   F       N            N       N   \n",
      "2        2    3428          Placebo  13727   F       N            Y       Y   \n",
      "3        3    2576          Placebo  18460   F       N            N       N   \n",
      "4        4     788          Placebo  16658   F       N            Y       N   \n",
      "...    ...     ...              ...    ...  ..     ...          ...     ...   \n",
      "7900  7900    1166  D-penicillamine  16839   F       N            N       N   \n",
      "7901  7901    1492          Placebo  17031   F       N            Y       N   \n",
      "7902  7902    1576  D-penicillamine  25873   F       N            N       Y   \n",
      "7903  7903    3584  D-penicillamine  22960   M       N            Y       N   \n",
      "7904  7904    1978  D-penicillamine  19237   F       N            N       N   \n",
      "\n",
      "     Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
      "0        N        2.3        316.0     3.35   172.0    1601.0  179.80   \n",
      "1        N        0.9        364.0     3.54    63.0    1440.0  134.85   \n",
      "2        Y        3.3        299.0     3.55   131.0    1029.0  119.35   \n",
      "3        N        0.6        256.0     3.50    58.0    1653.0   71.30   \n",
      "4        N        1.1        346.0     3.65    63.0    1181.0  125.55   \n",
      "...    ...        ...          ...      ...     ...       ...     ...   \n",
      "7900     N        0.8        309.0     3.56    38.0    1629.0   79.05   \n",
      "7901     N        0.9        260.0     3.43    62.0    1440.0  142.00   \n",
      "7902     S        2.0        225.0     3.19    51.0     933.0   69.75   \n",
      "7903     N        0.7        248.0     2.75    32.0    1003.0   57.35   \n",
      "7904     N        0.7        256.0     3.23    22.0     645.0   74.40   \n",
      "\n",
      "      Tryglicerides  Platelets  Prothrombin  Stage Status  \n",
      "0              63.0      394.0          9.7    3.0      D  \n",
      "1              88.0      361.0         11.0    3.0      C  \n",
      "2              50.0      199.0         11.7    4.0      D  \n",
      "3              96.0      269.0         10.7    3.0      C  \n",
      "4              96.0      298.0         10.6    4.0      C  \n",
      "...             ...        ...          ...    ...    ...  \n",
      "7900          224.0      344.0          9.9    2.0      C  \n",
      "7901           78.0      277.0         10.0    4.0      C  \n",
      "7902           62.0      200.0         12.7    2.0      D  \n",
      "7903          118.0      221.0         10.6    4.0      D  \n",
      "7904           85.0      336.0         10.3    3.0      C  \n",
      "\n",
      "[7905 rows x 20 columns]\n",
      "\n",
      "\n",
      "Dataset 2 - test.csv:\n",
      "         id  N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders  \\\n",
      "0      7905    3839  D-penicillamine  19724   F       N            Y       N   \n",
      "1      7906    2468  D-penicillamine  14975   F       N            N       N   \n",
      "2      7907      51          Placebo  13149   F       N            Y       N   \n",
      "3      7908    2330  D-penicillamine  20510   F       N            N       N   \n",
      "4      7909    1615  D-penicillamine  21904   F       N            Y       N   \n",
      "...     ...     ...              ...    ...  ..     ...          ...     ...   \n",
      "5266  13171    2870          Placebo  12279   F       N            N       N   \n",
      "5267  13172    1770          Placebo  24803   F       N            N       N   \n",
      "5268  13173    3707  D-penicillamine  16990   F       N            Y       N   \n",
      "5269  13174    1216          Placebo  11773   F       N            N       N   \n",
      "5270  13175    2272  D-penicillamine  21600   F       N            N       N   \n",
      "\n",
      "     Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
      "0        N        1.2        546.0     3.37    65.0    1636.0  151.90   \n",
      "1        N        1.1        660.0     4.22    94.0    1257.0  151.90   \n",
      "2        Y        2.0        151.0     2.96    46.0     961.0   69.75   \n",
      "3        N        0.6        293.0     3.85    40.0     554.0  125.55   \n",
      "4        N        1.4        277.0     2.97   121.0    1110.0  125.00   \n",
      "...    ...        ...          ...      ...     ...       ...     ...   \n",
      "5266     N        1.3        302.0     3.43    75.0    1345.0  145.00   \n",
      "5267     N        0.5        219.0     4.09   121.0     663.0   79.05   \n",
      "5268     N        0.8        315.0     4.09    13.0    1637.0  170.50   \n",
      "5269     N        0.7        329.0     3.80    52.0     678.0   57.00   \n",
      "5270     N        2.0        232.0     3.42    18.0    1636.0  170.50   \n",
      "\n",
      "      Tryglicerides  Platelets  Prothrombin  Stage  \n",
      "0              90.0      430.0         10.6    2.0  \n",
      "1             155.0      227.0         10.0    2.0  \n",
      "2             101.0      213.0         13.0    4.0  \n",
      "3              56.0      270.0         10.6    2.0  \n",
      "4             126.0      221.0          9.8    1.0  \n",
      "...             ...        ...          ...    ...  \n",
      "5266           44.0      181.0         10.6    3.0  \n",
      "5267           94.0      311.0          9.7    3.0  \n",
      "5268           70.0      426.0         10.9    3.0  \n",
      "5269          126.0      306.0         10.2    1.0  \n",
      "5270           83.0      213.0         13.6    2.0  \n",
      "\n",
      "[5271 rows x 19 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DATA PATH\n",
    "data_paths = [\n",
    "    \"train.csv\",\n",
    "    \"test.csv\"\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "# READ DATA\n",
    "df = [pd.read_csv(f\"C:\\\\Users\\\\nh013\\\\Desktop\\\\Multi-Class Prediction of Cirrhosis Outcomes\\\\{path}\") for path in data_paths]\n",
    "\n",
    "# PRINT DATASET \n",
    "for i, df in enumerate(df):\n",
    "    print(f\"Dataset {i + 1} - {data_paths[i]}:\")\n",
    "    print(df)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f4bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc923a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in DataFrame 1:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Missing Values in DataFrame 2:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Categorical Columns in DataFrame 1:\n",
      "Index(['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', 'Status'], dtype='object')\n",
      "\n",
      "Categorical Columns in DataFrame 2:\n",
      "Index(['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DATA PATH\n",
    "data_paths = [\n",
    "    \"train.csv\",\n",
    "    \"test.csv\"\n",
    "]\n",
    "\n",
    "# READ DATA\n",
    "df = [pd.read_csv(f\"C:\\\\Users\\\\nh013\\\\Desktop\\\\Multi-Class Prediction of Cirrhosis Outcomes\\\\{path}\") for path in data_paths]\n",
    "\n",
    "# CHECK MISSING VALUES\n",
    "for i, data_frame in enumerate(df):\n",
    "    missing_values = data_frame.isnull().sum()\n",
    "    print(f\"\\nMissing Values in DataFrame {i + 1}:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "# CHECK FOR CATEGORICAL COL\n",
    "for i, data_frame in enumerate(df):\n",
    "    categorical_columns = data_frame.select_dtypes(include=['object']).columns\n",
    "    print(f\"\\nCategorical Columns in DataFrame {i + 1}:\")\n",
    "    print(categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780a221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e62d9e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "         id    N_Days  Drug       Age  Sex  Ascites  Hepatomegaly  Spiders  \\\n",
      "0  0.000000  0.201515   0.0  0.626391  1.0      0.0           0.0      0.0   \n",
      "1  0.000076  0.532814   1.0  0.505931  0.0      0.0           0.0      0.0   \n",
      "2  0.000152  0.712453   1.0  0.216723  0.0      0.0           1.0      1.0   \n",
      "3  0.000228  0.533235   1.0  0.465148  0.0      0.0           0.0      0.0   \n",
      "4  0.000304  0.157131   1.0  0.370565  0.0      0.0           1.0      0.0   \n",
      "\n",
      "   Edema  Bilirubin  Cholesterol   Albumin    Copper  Alk_Phos      SGOT  \\\n",
      "0    0.0   0.072202     0.118429  0.518657  0.287671  0.096660  0.356115   \n",
      "1    0.0   0.021661     0.147432  0.589552  0.101027  0.084798  0.251799   \n",
      "2    1.0   0.108303     0.108157  0.593284  0.217466  0.054518  0.215827   \n",
      "3    0.0   0.010830     0.082175  0.574627  0.092466  0.100491  0.104317   \n",
      "4    0.0   0.028881     0.136556  0.630597  0.101027  0.065717  0.230216   \n",
      "\n",
      "   Tryglicerides  Platelets  Prothrombin     Stage    Status  \n",
      "0       0.053097   0.662675     0.077778  0.666667  0.666667  \n",
      "1       0.097345   0.596806     0.222222  0.666667  0.000000  \n",
      "2       0.030088   0.273453     0.300000  1.000000  0.666667  \n",
      "3       0.111504   0.413174     0.188889  0.666667  0.000000  \n",
      "4       0.111504   0.471058     0.177778  1.000000  0.000000  \n",
      "\n",
      "Test Data:\n",
      "            id    N_Days  Drug       Age  Sex  Ascites  Hepatomegaly  Spiders  \\\n",
      "7905  0.600000  0.798906   0.0  0.531493  0.0      0.0           1.0      0.0   \n",
      "7906  0.600076  0.510517   0.0  0.282228  0.0      0.0           0.0      0.0   \n",
      "7907  0.600152  0.002103   1.0  0.186385  0.0      0.0           1.0      0.0   \n",
      "7908  0.600228  0.481489   0.0  0.572748  0.0      0.0           0.0      0.0   \n",
      "7909  0.600304  0.331090   0.0  0.645916  0.0      0.0           1.0      0.0   \n",
      "\n",
      "      Edema  Bilirubin  Cholesterol   Albumin    Copper  Alk_Phos      SGOT  \\\n",
      "7905    0.0   0.032491     0.257402  0.526119  0.104452  0.099238  0.291367   \n",
      "7906    0.0   0.028881     0.326284  0.843284  0.154110  0.071316  0.291367   \n",
      "7907    1.0   0.061372     0.018731  0.373134  0.071918  0.049509  0.100719   \n",
      "7908    0.0   0.010830     0.104532  0.705224  0.061644  0.019523  0.230216   \n",
      "7909    0.0   0.039711     0.094864  0.376866  0.200342  0.060486  0.228939   \n",
      "\n",
      "      Tryglicerides  Platelets  Prothrombin     Stage  Status  \n",
      "7905       0.100885   0.734531     0.177778  0.333333     1.0  \n",
      "7906       0.215929   0.329341     0.111111  0.333333     1.0  \n",
      "7907       0.120354   0.301397     0.444444  1.000000     1.0  \n",
      "7908       0.040708   0.415170     0.177778  0.333333     1.0  \n",
      "7909       0.164602   0.317365     0.088889  0.000000     1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# DATA PATH\n",
    "data_paths = [\n",
    "    \"train.csv\",\n",
    "    \"test.csv\"\n",
    "]\n",
    "\n",
    "# READ DATA\n",
    "df = [pd.read_csv(f\"C:\\\\Users\\\\nh013\\\\Desktop\\\\Multi-Class Prediction of Cirrhosis Outcomes\\\\{path}\") for path in data_paths]\n",
    "\n",
    "# COMBINE TRAIN AND TEST DATA FOR PREPROCESSING \n",
    "df_combined = pd.concat(df, axis=0, ignore_index=True)\n",
    "\n",
    "# DROP DUPLICATES ROWS\n",
    "df_combined = df_combined.drop_duplicates()\n",
    "\n",
    "# CONVERT CATEGORICAL TO NUMERICAL USING LABEL ENCODER\n",
    "label_encoder = LabelEncoder()\n",
    "for col in df_combined.select_dtypes(include='object').columns:\n",
    "    df_combined[col] = label_encoder.fit_transform(df_combined[col])\n",
    "\n",
    "# CONVET STRING TO FLOAT  \n",
    "for col in df_combined.columns:\n",
    "    if df_combined[col].dtype == 'object':\n",
    "        try:\n",
    "            df_combined[col] = df_combined[col].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        \n",
    "# HANDLEING OUTLIERS USING Z SCORE \n",
    "z_scores = zscore(df_combined.select_dtypes(include=['int64', 'float64']))\n",
    "abs_z_scores = abs(z_scores)\n",
    "outlier_rows = (abs_z_scores > 3).all(axis=1)\n",
    "df_combined = df_combined[~outlier_rows]\n",
    "\n",
    "# IMPUTE MISSING VALUES\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_combined = pd.DataFrame(imputer.fit_transform(df_combined), columns=df_combined.columns)\n",
    "\n",
    "# NORMALIZE AND SCALE \n",
    "scaler = MinMaxScaler()\n",
    "df_combined[df_combined.columns] = scaler.fit_transform(df_combined[df_combined.columns])\n",
    "\n",
    "\n",
    "# SPLIT THE DATA BACK INTO TRAIN AND TEST SET \n",
    "df_train = df_combined.iloc[:len(df[0]), :]\n",
    "df_test = df_combined.iloc[len(df[0]):, :]\n",
    "\n",
    "\n",
    "print(\"Train Data:\")\n",
    "print(df_train.head())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6dbb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "883f3729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (10540, 19) (10540,)\n",
      "Testing set shape: (2636, 19) (2636,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# DATA PATH\n",
    "data_paths = [\n",
    "    \"train.csv\",\n",
    "    \"test.csv\"\n",
    "]\n",
    "\n",
    "# READ DATA\n",
    "df = [pd.read_csv(f\"C:\\\\Users\\\\nh013\\\\Desktop\\\\Multi-Class Prediction of Cirrhosis Outcomes\\\\{path}\") for path in data_paths]\n",
    "\n",
    "# COMBINE TRAIN AND TEST DATA FOR PREPROCESSING \n",
    "df_combined = pd.concat(df, axis=0, ignore_index=True)\n",
    "\n",
    "# DROP DUPLICATES ROWS\n",
    "df_combined = df_combined.drop_duplicates()\n",
    "\n",
    "# CONVERT CATEGORICAL TO NUMERICAL USING LABEL ENCODER\n",
    "label_encoder = LabelEncoder()\n",
    "for col in df_combined.select_dtypes(include='object').columns:\n",
    "    df_combined[col] = label_encoder.fit_transform(df_combined[col])\n",
    "\n",
    "# CONVERT STRING TO FLOAT  \n",
    "for col in df_combined.columns:\n",
    "    if df_combined[col].dtype == 'object':\n",
    "        try:\n",
    "            df_combined[col] = df_combined[col].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "# HANDLEING OUTLIERS USING Z SCORE \n",
    "z_scores = zscore(df_combined.select_dtypes(include=['int64', 'float64']))\n",
    "abs_z_scores = abs(z_scores)\n",
    "outlier_rows = (abs_z_scores > 3).all(axis=1)\n",
    "df_combined = df_combined[~outlier_rows]\n",
    "\n",
    "# IMPUTE MISSING VALUES\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_combined = pd.DataFrame(imputer.fit_transform(df_combined), columns=df_combined.columns)\n",
    "\n",
    "# NORMALIZE AND SCALE \n",
    "scaler = MinMaxScaler()\n",
    "df_combined[df_combined.columns] = scaler.fit_transform(df_combined[df_combined.columns])\n",
    "\n",
    "# SPLIT THE DATA BACK INTO TRAIN AND TEST SET \n",
    "X = df_combined.drop('Status', axis=1)  # FEATURE\n",
    "y = df_combined['Status']  # TARGET VARIABLE\n",
    "\n",
    "#SPLIT THE DATA INTO TRAINING AND TESTING SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0bab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f03119d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc27886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63535f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e637e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8943210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Training Set Performance:\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6342\n",
      "           1       1.00      1.00      1.00      4198\n",
      "\n",
      "    accuracy                           1.00     10540\n",
      "   macro avg       1.00      1.00      1.00     10540\n",
      "weighted avg       1.00      1.00      1.00     10540\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6342    0]\n",
      " [   0 4198]]\n",
      "\n",
      "Testing Set Performance:\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1563\n",
      "           1       1.00      1.00      1.00      1073\n",
      "\n",
      "    accuracy                           1.00      2636\n",
      "   macro avg       1.00      1.00      1.00      2636\n",
      "weighted avg       1.00      1.00      1.00      2636\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1563    0]\n",
      " [   0 1073]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# DATA PATH\n",
    "data_paths = [\n",
    "    \"train.csv\",\n",
    "    \"test.csv\"\n",
    "]\n",
    "\n",
    "# READ DATA\n",
    "df = [pd.read_csv(f\"C:\\\\Users\\\\nh013\\\\Desktop\\\\Multi-Class Prediction of Cirrhosis Outcomes\\\\{path}\") for path in data_paths]\n",
    "\n",
    "# COMBINE TRAIN AND TEST DATA FOR PREPROCESSING \n",
    "df_combined = pd.concat(df, axis=0, ignore_index=True)\n",
    "\n",
    "# DROP DUPLICATES ROWS\n",
    "df_combined = df_combined.drop_duplicates()\n",
    "\n",
    "# CONVERT CATEGORICAL TO NUMERICAL USING LABEL ENCODER\n",
    "label_encoder = LabelEncoder()\n",
    "for col in df_combined.select_dtypes(include='object').columns:\n",
    "    df_combined[col] = label_encoder.fit_transform(df_combined[col])\n",
    "\n",
    "# CONVERT STRING TO FLOAT  \n",
    "for col in df_combined.columns:\n",
    "    if df_combined[col].dtype == 'object':\n",
    "        try:\n",
    "            df_combined[col] = df_combined[col].astype(float)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "# HANDLE OUTLIERS USING Z SCORE \n",
    "z_scores = zscore(df_combined.select_dtypes(include=['int64', 'float64']))\n",
    "abs_z_scores = abs(z_scores)\n",
    "outlier_rows = (abs_z_scores > 3).all(axis=1)\n",
    "df_combined = df_combined[~outlier_rows]\n",
    "\n",
    "# IMPUTE MISSING VALUES\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_combined = pd.DataFrame(imputer.fit_transform(df_combined), columns=df_combined.columns)\n",
    "\n",
    "# NORMALIZE AND SCALE \n",
    "scaler = MinMaxScaler()\n",
    "df_combined[df_combined.columns] = scaler.fit_transform(df_combined[df_combined.columns])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CONVERT 'Status' TO INTEGER\n",
    "df_combined['Status'] = df_combined['Status'].astype(int)\n",
    "\n",
    "# SPLIT THE DATA BACK INTO TRAIN AND TEST SET \n",
    "X = df_combined.drop('Status', axis=1)  # FEATURES\n",
    "y = df_combined['Status']  # TARGET VARIABLE\n",
    "\n",
    "# SPLIT THE DATA INTO TRAINING AND TESTING SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# RANDOM FOREST MODEL\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# HYPERPARAMETER TUNING\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# BEST PARAMETERS\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# TRAIN THE MODEL WITH BEST PARAMETERS\n",
    "best_rf_model = RandomForestClassifier(**best_params)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTIONS\n",
    "y_pred_train = best_rf_model.predict(X_train)\n",
    "y_pred_test = best_rf_model.predict(X_test)\n",
    "\n",
    "# EVALUATION\n",
    "print(\"\\nTraining Set Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Classification Report:\\n\", classification_report(y_train, y_pred_train))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_train, y_pred_train))\n",
    "\n",
    "print(\"\\nTesting Set Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51869495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
